---
title: "Blog_teste"
author: "Humberto Silva"
date: "17/04/2020"
output: html_document
---

```{r setup, include=FALSE}
version <- "1.8"
version_date <- lubridate::ymd("2020-02-28")

knitr::opts_chunk$set(echo = FALSE, cache=TRUE,
                      tidy.opts=list(width.cutoff=60),
                      tidy=TRUE)
library(tidyverse)
library(magrittr)
library(lubridate)
library(tibble)
library(ggplot2)
library(ggthemes)
library(hrbrthemes)
library(rvest)
library(gt)
library(deSolve)
library(EpiEstim)
library(incidence)
library(distcrete)
library(epitrix)
library(projections)
library(formatR)

```

## Coronavirus: The case of Portugal

This post was made for didatical purposes and intends to help a better understand about how is possible to study this disease, in particular the portuguese case.
This was inspired in the reading of https://blog.ephorie.de/epidemiology-how-contagious-is-novel-coronavirus-2019-ncov?fbclid=IwAR35_eyO1Ry6Bru04WKKPNv7mxt5rhNT_liU6QlEqJ8u-BrOZoVHxxJ0jbM, wich I am giving the credits for this work.
First of all my academic background is Biotecnology and Chemistry, so I have some concepts, however not specialized in epidemioloy, thus wanted to improve my knowlege about this theme. I choosed to use the software R for the calculations and models for the data.

So the first question is how is possible for the epidmiologists to predict how contagiouse a virus is?

There are diverse models available so here I will use the simpliest and very well known SIR model (ver wikipedia).
All the numbers I will use for this study come from the oficial authorities from the start point. The further analyses is mine.

Why is so important to have insights about this? The health and economy are two faces of any epidemie. 
In one hand We need to save lives and in the other we need to maintain our jobs, social services, and keep all the activities that we need to survive (agriculture, industry, services and others) so kill all the economy it's not desirable too. 
How do we achieve this balance? In my opinion a main effort should be made in saving lives So the measures should be so restritive as necessary to avoid the colapse of the health system .

In wich phase of infection we are in Portugal so far?
So we need to analyse the confirmed Cases acumulated in time. Let's do it.


First we need to find a credible source available. Because the data in DGS are in PDF files we need a better solution to quikly acquiring data in a automatic way from the WEB. Unfortantly, the code works in this html source (https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos) but if the layout is changed, we need rearrange the code for another source and to have that in mind. Another solution is insert the values in a .CSV file, .txt file or manually but I will not dive in it.

```{r Scraping HTML Tables, include=FALSE}

# download the wikipedia web page

# we use a specific version of the template page directly
# version of the wikipedia page that is used by this version of this document
portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"

# unversioned page
# portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"
portuguese_outbreak_webpage <- read_html(portuguese_wikipedia_data_url)

# read tables
tbls <- html_nodes(portuguese_outbreak_webpage, "table")

head(tbls)

tbls_ls <- portuguese_outbreak_webpage %>%
  html_nodes("table") %>%
  .[5:6] %>%
  html_table(fill = TRUE)

# verification of the parameters of the table
str(tbls_ls)
head (tbls_ls)


# remove row 1 that includes part of the headings
tbls_ls[[1]] <- tbls_ls[[1]][-2]

# remove row 1 that includes part of the headings

tbls_ls[[1]]<- tbls_ls[[2]][-1,]
tbls_ls[[1]]

#last_date_j <- ymd("2020-03-01")

# download the wikipedia web page

# we use a specific version of the template page directly
# version of the wikipedia page that is used by this version of this document
portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"

# unversioned page
# portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"
portuguese_outbreak_webpage <- read_html(portuguese_wikipedia_data_url)

# read tables
tbls <- html_nodes(portuguese_outbreak_webpage, "table")

#head(tbls)

tbls_ls <- portuguese_outbreak_webpage %>%
  html_nodes("table") %>%
  .[5:6] %>%
  html_table(fill = TRUE)

# verification of the parameters of the table
#str(tbls_ls)
#head (tbls_ls)

# remove row 1 that includes part of the headings
tbls_ls[[1]] <- tbls_ls[[1]][-2]

# remove row 1 that includes part of the headings

tbls_ls[[1]]<- tbls_ls[[2]][-1,]
tbls_ls[[1]]

# rename table headings
colnames(tbls_ls[[1]]) <- c("Date", "Confirmed Cases")

#atribute values
Infected<-tbls_ls[[1]]$`Confirmed Cases`

#convert date in Char to date format

Date <-tbls_ls[[1]]$`Date`

Date<-seq(as.Date('2020-03-03'), as.Date('2020-12-31'), by = 'days') 

#Date <- as_tibble(Date)
```

```{r infected}
#Inseri os valores de Portugal até dia 17-04-2020:

Day <- 1:(length(Infected))
N <- 10000000 # população de Portugal
 
old <- par(mfrow = c(1, 2))
plot(Day, Infected, type ="b")
plot(Day, Infected, log = "y")
#abline(lm(log10(Infected) ~ Dia))
title("Cumulative confirmed cases 2020-Portugal", outer = TRUE, line = -2)

```

The graphic in the left is the number of infected people by time and in the right the same but with a log scale on the y-axis (a log-linear plot), and seems that the curve is flatening showing Portugal finished the exponecial growth phase, or the rate of growth is much more slower now. We will see more in detail this point. 
Now we come to the prediction part with the SIR model, which basic idea is quite simple. There are three groups of people: those that are healthy but susceptible to the disease (S), the infected (I) and the people who have recovered (R):


Source: wikimedia
To model the dynamics of the outbreak we need three differential equations, one for the change in each group, where \beta is the parameter that controls the transition between S and I and \gamma which controls the transition between I and R:

  \[\frac{dS}{dt} = - \frac{\beta I S}{N}\]

  \[\frac{dI}{dt} = \frac{\beta I S}{N}- \gamma I\]

  \[\frac{dR}{dt} = \gamma I\]

This can easily be put into R code:
```{r SIR MODEL, include=TRUE}
SIR <- function(time, state, parameters) {
  par <- as.list(c(state, parameters))
  with(par, {
    dS <- -beta/N * I * S
    dI <- beta/N * I * S - gamma * I
    dR <- gamma * I
    list(c(dS, dI, dR))
    })
}
```

To fit the model to the data we need two things: a solver for differential equations and an optimizer. To solve differential equations the function ode from the deSolve package (on CRAN) is an excellent choice, to optimize we will use the optim function from base R. Concretely, we will minimize the sum of the squared differences between the number of infected I at time t and the corresponding number of predicted cases by our model \^{I}(t):

  \[RSS(\beta, \gamma) = \sum_{t} \left( I(t)-\^{I}(t) \right)^2\]

Putting it all together:
```{r optimization, include=TRUE}

#library(deSolve)
init <- c(S = N-Infected[1], I = Infected[1], R = 0)
RSS <- function(parameters) {
  names(parameters) <- c("beta", "gamma")
  out <- ode(y = init, times = Day, func = SIR, parms = parameters)
  fit <- out[ , 3]
  sum((Infected - fit)^2)
}
 
Opt <- optim(c(0.5, 0.5), RSS, method = "L-BFGS-B", lower = c(0, 0), upper = c(1, 1)) # optimize with some sensible conditions
Opt$message
#[1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"
 
Opt_par <- setNames(Opt$par, c("beta", "gamma"))
Opt_par
##      beta     gamma 
## 0.6746089 0.3253912
 
t <- 1:100 # time in days
fit <- data.frame(ode(y = init, times = t, func = SIR, parms = Opt_par))
col <- 1:3 # colour
 
matplot(fit$time, fit[ , 2:4], type = "l", xlab = "Day", ylab = "Number of subjects", lwd = 2, lty = 1, col = col)
matplot(fit$time, fit[ , 2:4], type = "l", xlab = "Day", ylab = "Number of subjects", lwd = 2, lty = 1, col = col, log = "y")
## Warning in xy.coords(x, y, xlabel, ylabel, log = log): 1 y value <= 0
## omitted from logarithmic plot
 
points(Day, Infected)
legend("bottomright", c("Susceptibles", "Infecteds", "Recovereds"), lty = 1, lwd = 2, col = col, inset = 0.05)
title("SIR model COVID19 Portugal", outer = TRUE, line = -2)
```

So observing our experimental points until 19-04-2020, we conclude this model it's not fiting very well. This can happen because it's too simplist to explain the behavior of the infection at this stage, it doesn't include the containment measures efects. 
However from the literature we know that in the begining the growth rate is exponencial and so let's check if the model can predict if nothing was been done. We going to rebuid only with the days until 20-03-2020, assuming that in this phase we were having transmission in the comunity in average 14 days before the people have syntomes actualy having positive tests. 

```{r optimization2, include=FALSE}

#select data until day 20-03-2020, exponecial growth rate


# download the wikipedia web page

# we use a specific version of the template page directly
# version of the wikipedia page that is used by this version of this document
portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"

# unversioned page
# portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"
portuguese_outbreak_webpage <- read_html(portuguese_wikipedia_data_url)

# read tables
tbls <- html_nodes(portuguese_outbreak_webpage, "table")

head(tbls)

tbls_ls <- portuguese_outbreak_webpage %>%
  html_nodes("table") %>%
  .[5:6] %>%
  html_table(fill = TRUE)

# verification of the parameters of the table
str(tbls_ls)
head (tbls_ls)
#até aqui funciona!!

# remove row 1 that includes part of the headings
tbls_ls[[1]] <- tbls_ls[[1]][-2]

# remove row 1 that includes part of the headings

tbls_ls[[1]]<- tbls_ls[[2]][-1,]
tbls_ls[[1]]

# download the wikipedia web page

# we use a specific version of the template page directly
# version of the wikipedia page that is used by this version of this document
portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"

# unversioned page
# portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"
portuguese_outbreak_webpage <- read_html(portuguese_wikipedia_data_url)

# read tables
tbls <- html_nodes(portuguese_outbreak_webpage, "table")

#head(tbls)

tbls_ls <- portuguese_outbreak_webpage %>%
  html_nodes("table") %>%
  .[5:6] %>%
  html_table(fill = TRUE)

# verification of the parameters of the table
#str(tbls_ls)
#head (tbls_ls)

# remove row 1 that includes part of the headings
tbls_ls[[1]] <- tbls_ls[[1]][-2]

# remove row 1 that includes part of the headings

tbls_ls[[1]]<- tbls_ls[[2]][-1,]


# rename table headings
colnames(tbls_ls[[1]]) <- c("Date", "Confirmed Cases")

#atribute values
Infected<-tbls_ls[[1]]$`Confirmed Cases`

#convert date in Char to date format

Date <-tbls_ls[[1]]$`Date`

Date<-seq(as.Date('2020-03-03'), as.Date('2020-03-20'), by = 'days') 

Infected<-Infected[1:18]

#tbls_ls[[1]]$`Date`<- Date

#select data until day 20-03-2020, exponecial growth rate
data.frame<-data.frame(Date,Infected)

Infected<-data.frame[data.frame$Infected <=1220, ]

Date<-data.frame$Date

Infected<-data.frame$Infected

#atribute values without intervention or social distancing
Infected_exp<-Infected

#Inseri os valores de Portugal até dia 20-03-2020:

Day <- 1:(length(Infected))
N <- 10000000 # população de Portugal
 
old <- par(mfrow = c(1, 2))
plot(Day, Infected, type ="b")
plot(Day, Infected, log = "y")
#abline(lm(log10(Infected) ~ Dia))
title("Cumulative confirmed cases 2020-Portugal", outer = TRUE, line = -2)

SIR <- function(time, state, parameters) {
  par <- as.list(c(state, parameters))
  with(par, {
    dS <- -beta/N * I * S
    dI <- beta/N * I * S - gamma * I
    dR <- gamma * I
    list(c(dS, dI, dR))
    })
}



#library(deSolve)
init <- c(S = N-Infected_exp[1], I = Infected_exp[1], R = 0)
RSS <- function(parameters) {
  names(parameters) <- c("beta", "gamma")
  out <- ode(y = init, times = Day, func = SIR, parms = parameters)
  fit <- out[ , 3]
  sum((Infected_exp - fit)^2)
}
 
Opt <- optim(c(0.5, 0.5), RSS, method = "L-BFGS-B", lower = c(0, 0), upper = c(1, 1)) # optimize with some sensible conditions
Opt$message
#[1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"
 
Opt_par <- setNames(Opt$par, c("beta", "gamma"))
Opt_par
#beta     gamma 
## 0.6746089 0.3253912
 
```
```{r pressure, echo=FALSE}
t <- 1:100 # time in days
fit <- data.frame(ode(y = init, times = t, func = SIR, parms = Opt_par))
col <- 1:3 # colour
 
matplot(fit$time, fit[ , 2:4], type = "l", xlab = "Day", ylab = "Number of subjects", lwd = 2, lty = 1, col = col)
matplot(fit$time, fit[ , 2:4], type = "l", xlab = "Day", ylab = "Number of subjects", lwd = 2, lty = 1, col = col, log = "y")
## Warning in xy.coords(x, y, xlabel, ylabel, log = log): 1 y value <= 0
## omitted from logarithmic plot
 
points(Day, Infected_exp)
legend("bottomright", c("Susceptibles", "Infecteds", "Recovereds"), lty = 1, lwd = 2, col = col, inset = 0.05)
title("SIR model COVID19 Portugal", outer = TRUE, line = -2)
```

We have a good fitting now, not perfect indeed as noticed before for the same reasons: it's too simplistic. Thus giving us a first aproximation to the reality, and permit estimate some coeficients. 
Let's try to make it more realistic. We should keep in mind that a curve epidemic should be made with the "dates of begining of synthomes of the subjects" and here we are using the confirmed cases, so the quality of the data is very important.

We see in the right log-linear plot that the model seems to fit the values quite well. We can now extract some interesting statistics. One important number is the so-called basic reproduction number (also basic reproduction ratio) R_0 (pronounced “R naught”) which basically shows how many healthy people get infected by a sick person on average:

```{r Estimation R0, include=TRUE}
par(old)
 
R0 <- setNames(Opt_par["beta"] / Opt_par["gamma"], "R0")
R0
##       R0 
## 1.98384
 
fit[fit$I == max(fit$I), "I", drop = FALSE] # height of pandemic
##            I
## 37 616443.4
 
max(fit$I) * 0.02 # max deaths with supposed 2% fatality rate
## [1] 12328.87

```

So, R_0 is estimated in 1.9, which is consistent with the number that many researchers and the WHO give and which is around the same range of SARS, Influenza or Ebola (while transmission of Ebola is via bodily fluids and not airborne droplets).

Additionally, according to this model, the height of a possible pandemic would be reached a around 08-04-2020 (37 days after it started) with over 616 thousand people infected around 12329 dead. As discussed before this would be the worst case scenario that we already know it's not the real situation because don't include the variable for social distancing (so this numbers are too high). 
So don't panic let's try to make a better model for portuguese case.
```{r SIR_model_fitted_data, include = FALSE, echo=FALSE, tidy=FALSE, message=TRUE}
# we use a specific version of the template page directly
# version of the wikipedia page that is used by this version of this document
portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"

# unversioned page
# portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"
portuguese_outbreak_webpage <- read_html(portuguese_wikipedia_data_url)

# read tables
tbls <- html_nodes(portuguese_outbreak_webpage, "table")

head(tbls)

tbls_ls <- portuguese_outbreak_webpage %>%
  html_nodes("table") %>%
  .[5:6] %>%
  html_table(fill = TRUE)

# verification of the parameters of the table
str(tbls_ls)
head (tbls_ls)
#até aqui funciona!!

# remove row 1 that includes part of the headings
tbls_ls[[1]] <- tbls_ls[[1]][-2]

# remove row 1 that includes part of the headings

tbls_ls[[1]]<- tbls_ls[[2]][-1,]
tbls_ls[[1]]

last_date_j <- ymd("2020-03-01")

# download the wikipedia web page

# we use a specific version of the template page directly
# version of the wikipedia page that is used by this version of this document
portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"

# unversioned page
# portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"
portuguese_outbreak_webpage <- read_html(portuguese_wikipedia_data_url)

# read tables
tbls <- html_nodes(portuguese_outbreak_webpage, "table")

#head(tbls)

tbls_ls <- portuguese_outbreak_webpage %>%
  html_nodes("table") %>%
  .[5:6] %>%
  html_table(fill = TRUE)

# verification of the parameters of the table
#str(tbls_ls)
#head (tbls_ls)

# remove row 1 that includes part of the headings
tbls_ls[[1]] <- tbls_ls[[1]][-2]

# remove row 1 that includes part of the headings

tbls_ls[[1]]<- tbls_ls[[2]][-1,]


# rename table headings
colnames(tbls_ls[[1]]) <- c("Date", "Confirmed Cases")

#atribute values
Infected<-tbls_ls[[1]]$`Confirmed Cases`

#convert date in Char to date format

#Date <-tbls_ls[[1]]$`Date`

Date<-seq(as.Date('2020-03-03'), as.Date('2020-03-20'), by = 'days') 

Infected<-Infected[1:18]

date<-Date
cumulative_incidence<-Infected
#tbls_ls[[1]]$`Date`<- Date

#funciona
#select data until day 20-03-2020, exponecial growth rate
Incidence<-data.frame(date,cumulative_incidence)

SIR <- function(time, state, parameters) {
  par <- as.list(c(state, parameters))
  with(par, {
    dS <- -beta * I * S/N
    dI <- beta * I * S/N - gamma * I
    dR <- gamma * I
    list(c(dS, dI, dR))
  })
}


N<-10000000

#put the daily cumulative incidence numbers 
# 03th Mar to 20th Mar into a vector called Infected

sir_start_date <- "2020-03-03"


#(atribui os valores à variável "Infected" da coluna em questão: cumulative_incidence, da tabela "Incidence")

Infected<-Incidence$cumulative_incidence 



# Create an incrementing Day vector the same length as our
# cases vector
Day <- 1:(length(Infected))

# now specify initial values for S, I and R
init <- c(S = N - Infected[1], I = Infected[1], R = 0)

RSS <- function(parameters) {
  names(parameters) <- c("beta", "gamma")
  out <- ode(y = init, times = Day, func = SIR, parms = parameters)
  fit <- out[, 3]
  sum((Infected - fit)^2)
}



Opt <- optim(c(0.5, 0.5), RSS, method = "L-BFGS-B", lower = c(0, 
                                                              0), upper = c(1, 1))

# check for convergence
Opt$message
#-------
# Determinar parâmetros
Opt_par <- setNames(Opt$par, c("beta", "gamma"))
Opt_par

#-------

# time in days for predictions 



t <- 1:as.integer(today() - ymd(sir_start_date))

# get the fitted values from our SIR model

fitted_cumulative_incidence <- data.frame(ode(y = init, times = t, 
                                              func = SIR, parms = Opt_par))


fitted_cumulative_incidence <- fitted_cumulative_incidence %>% 
  mutate(Data = ymd(sir_start_date) + days(t - 1)) 


fitted_cumulative_incidence %>% filter(Data <= ymd("2020-03-20")) %>% 
  ggplot(aes(x = Data)) + geom_line(aes(y = I), colour = "red") + 
  geom_point(aes(y = Infected), colour = "blue") + 
  labs(y = "Casos positivos acumulados", title = "COVID-19 modelo vs incidência acumulada, Portugal", 
       subtitle = "(linha vermelha =incidência ajustada pelo modelo SIR,\n pontos azuis=casos confirmados laboratoriais)")

## estimar R0:



R0 <- setNames(Opt_par["beta"] / Opt_par["gamma"], "R0")
R0

```
```{r SIR_model_plot_fitted_data, include = TRUE}
fitted_cumulative_incidence <- data.frame(ode(y = init, times = t, 
                                              func = SIR, parms = Opt_par))


fitted_cumulative_incidence <- fitted_cumulative_incidence %>% 
  mutate(Data = ymd(sir_start_date) + days(t - 1)) 


fitted_cumulative_incidence %>% filter(Data <= ymd("2020-03-20")) %>% 
  ggplot(aes(x = Data)) + geom_line(aes(y = I), colour = "red") + 
  geom_point(aes(y = Infected), colour = "blue") + 
  labs(y = "Casos positivos acumulados", title = "COVID-19 modelo vs incidência acumulada, Portugal", 
       subtitle = "(linha vermelha =incidência ajustada pelo modelo SIR,\n pontos azuis=casos confirmados laboratoriais)")


```

##Estimating changes in the effective reproduction number


In Portugal it's not clear for now if we reach the pike but seems plausible in the last days. We aren't able to use so called log-linear models for estimating R0 instead we are going to estimate another parameter wich  is the Re, current effective reproduction number.
Instead, we will focus on one method, developed in 2013 by Anne Cori and colleagues at Imperial College, London, which permits estimation of the instantaneous effective reproduction number, which is exactly want we want in order to track the effectiveness of containment efforts. Full details are available in the original paper on the method, with extensions described in a later paper by Thompson et al..

```{r optimization3, include=FALSE}

# download the wikipedia web page

# we use a specific version of the template page directly
# version of the wikipedia page that is used by this version of this document
portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"

# unversioned page
# portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"
portuguese_outbreak_webpage <- read_html(portuguese_wikipedia_data_url)

# read tables
tbls <- html_nodes(portuguese_outbreak_webpage, "table")

head(tbls)

tbls_ls <- portuguese_outbreak_webpage %>%
  html_nodes("table") %>%
  .[5:6] %>%
  html_table(fill = TRUE)

# verification of the parameters of the table
str(tbls_ls)
head (tbls_ls)

# remove row 1 that includes part of the headings
tbls_ls[[1]] <- tbls_ls[[1]][-2]

# remove row 1 that includes part of the headings

tbls_ls[[1]]<- tbls_ls[[2]][-1,]
tbls_ls[[1]]

last_date_j <- ymd("2020-03-01")

# download the wikipedia web page

# we use a specific version of the template page directly
# version of the wikipedia page that is used by this version of this document
portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"

# unversioned page
# portuguese_wikipedia_data_url <- "https://pt.wikipedia.org/wiki/Pandemia_de_COVID-19_em_Portugal#Evolu%C3%A7%C3%A3o_dos_casos"
portuguese_outbreak_webpage <- read_html(portuguese_wikipedia_data_url)

# read tables
tbls <- html_nodes(portuguese_outbreak_webpage, "table")

#head(tbls)

tbls_ls <- portuguese_outbreak_webpage %>%
  html_nodes("table") %>%
  .[5:6] %>%
  html_table(fill = TRUE)

# verification of the parameters of the table
#str(tbls_ls)
#head (tbls_ls)

# remove row 1 that includes part of the headings
tbls_ls[[1]] <- tbls_ls[[1]][-2]

# remove row 1 that includes part of the headings

tbls_ls[[1]]<- tbls_ls[[2]][-1,]


# rename table headings
colnames(tbls_ls[[1]]) <- c("Date", "Confirmed Cases")

#atribute values
Infected<-tbls_ls[[1]]$`Confirmed Cases`

#convert date in Char to date format

#Date <-tbls_ls[[1]]$`Date`

Date<-seq(as.Date('2020-03-03'), as.Date('2020-03-20'), by = 'days') 

Infected<-Infected[1:18]

date<-Date
cumulative_incidence<-Infected
#tbls_ls[[1]]$`Date`<- Date


#select data until day 20-03-2020, exponecial growth rate
Incidence<-data.frame(date,cumulative_incidence)

###

SIR <- function(time, state, parameters) {
  par <- as.list(c(state, parameters))
  with(par, {
    dS <- -beta * I * S/N
    dI <- beta * I * S/N - gamma * I
    dR <- gamma * I
    list(c(dS, dI, dR))
  })
}



N<-10000000

#put the daily cumulative incidence numbers
# 03th Mar to 09th Apr into a vector called Infected

sir_start_date <- "2020-03-03"

#(atribui os valores à variável "Infected" da coluna em questão: cumulative_incidence, da tabela "Incidence")

Infected<-Incidence$cumulative_incidence 

Data<-Incidence$date

# Create an incrementing Day vector the same length as our
# cases vector
Day <- 1:(length(Infected))

# now specify initial values for S, I and R
init <- c(S = N - Infected[1], I = Infected[1], R = 0)

RSS <- function(parameters) {
  names(parameters) <- c("beta", "gamma")
  out <- ode(y = init, times = Day, func = SIR, parms = parameters)
  fit <- out[, 3]
  sum((Infected - fit)^2)
}



Opt <- optim(c(0.5, 0.5), RSS, method = "L-BFGS-B", lower = c(0, 0), upper = c(1, 1))

# check for convergence
Opt$message

#-------
# Determinar parâmetros
Opt_par <- setNames(Opt$par, c("beta", "gamma"))
Opt_par

## estimar R0:

R0 <- setNames(Opt_par["beta"] / Opt_par["gamma"], "R0")
R0

#-------

# time in days for predictions 



t <- 1:120
```
```{r plot_incidence, include = TRUE}
# get the fitted values from our SIR model

fitted_cumulative_incidence <- data.frame(ode(y = init, times = t, 
                                              func = SIR, parms = Opt_par))


fitted_cumulative_incidence <- fitted_cumulative_incidence %>% 
  mutate(Data = ymd(sir_start_date) + days(t - 1)) 


fitted_cumulative_incidence %>% 
  ggplot(aes(x=Data)) + geom_line(aes(y=I), colour="red") +
  #geom_point(aes(y=Infected), colour="blue") +
  scale_y_continuous(labels = scales::comma) +
  labs(y="Incidência acumulada", 
       title="COVID-19 modelo vs incidência acumulada, Portugal",
       subtitle="(linha vermelha =incidência ajustada pelo modelo SIR,\n pontos azuis=casos confirmados laboratoriais)")
```

